{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRB rating machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.24.1\n",
    "%pip install pandas==1.5.3\n",
    "%pip install seaborn==0.12.2\n",
    "%pip install scikit-learn==1.2.0\n",
    "%pip install plotly==5.12.0\n",
    "%pip install matplotlib==3.6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import general libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV file with the ESRB rating data\n",
    "df = pd.read_csv('Video_games_esrb_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting typo in the original dataframe\n",
    "df = df.rename(columns={\"strong_janguage\": \"strong_language\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all columns\n",
    "# check if there are no missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the title and console columns, because it is not needed for the analysis\n",
    "df.drop(['title', 'console'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df['esrb_rating'].unique()\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the ESRB ratings with numbers, this is needed for some of the models\n",
    "df['esrb_rating'] = df['esrb_rating'].replace(\n",
    "    'E', 0).replace('ET', 1).replace('T', 2).replace('M', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['esrb_rating']\n",
    "X = df.drop(['esrb_rating'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and test sets\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree (Anwar Ammor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', splitter='random', max_depth=13, random_state=SEED)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_tree = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print feature importance\n",
    "features_df = pd.DataFrame(\n",
    "    {'features': classifier.feature_names_in_, 'importances': classifier.feature_importances_})\n",
    "\n",
    "# Sorting data from highest to lowest\n",
    "features_df_sorted = features_df.sort_values(by='importances', ascending=False)\n",
    "\n",
    "# Barplot of the result without borders and axis lines\n",
    "g = sns.barplot(data=features_df_sorted, x='importances',\n",
    "                y='features', palette=\"rocket\")\n",
    "sns.despine(bottom=True, left=True)\n",
    "g.set_title('Feature importances')\n",
    "g.set(xlabel=None)\n",
    "g.set(ylabel=None)\n",
    "g.set(xticks=[])\n",
    "for value in g.containers:\n",
    "    g.bar_label(value, padding=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn.tree built-in tree plot\n",
    "plt.figure(figsize=(140, 100))  # size of figure\n",
    "plot = tree.plot_tree(\n",
    "    decision_tree=classifier,   # classifier\n",
    "    feature_names=list(df.columns.values),\n",
    "    class_names=ratings,\n",
    "    fontsize=14,\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "\n",
    "# Save img\n",
    "# plt.savefig(\"Decision_tree.jpeg\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Remco de Wilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create instance of random forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=37,\n",
    "                             max_depth=17,\n",
    "                             random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "rfc.fit(X_train, y_train)\n",
    "# Predict the labels of the test set\n",
    "y_pred_rt = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.values  # The name of each column\n",
    "\n",
    "for estimator in rfc.estimators_:\n",
    "    print(estimator)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    tree.plot_tree(estimator,\n",
    "                   feature_names=features,\n",
    "                   class_names=ratings,\n",
    "                   fontsize=8,\n",
    "                   filled=True,\n",
    "                   rounded=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rt)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens').set_title('ESRB Rating')\n",
    "\n",
    "print(classification_report(y_test,y_pred_rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred_rt))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred_rt))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred_rt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "\n",
    "mcm = multilabel_confusion_matrix(y_test, y_pred_rt)\n",
    "\n",
    "for confusion_matrix in mcm:\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix, display_labels=['T','F'])\n",
    "    disp.plot(include_values=True, cmap=\"Greens\", ax=None, xticks_rotation=\"vertical\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the features and their importance\n",
    "features_df = pd.DataFrame(\n",
    "    {'features': rfc.feature_names_in_, 'importances': rfc.feature_importances_})\n",
    "\n",
    "# Sorting data from highest to lowest\n",
    "features_df_sorted = features_df.sort_values(by='importances', ascending=False)\n",
    "\n",
    "# Barplot of the result without borders and axis lines\n",
    "g = sns.barplot(data=features_df_sorted, x='importances',\n",
    "                y='features', palette=\"rocket\")\n",
    "sns.despine(bottom=True, left=True)\n",
    "g.set_title('Feature importances')\n",
    "g.set(xlabel=None)\n",
    "g.set(ylabel=None)\n",
    "g.set(xticks=[])\n",
    "for value in g.containers:\n",
    "    g.bar_label(value, padding=20)\n",
    "    g.margins(y=0.005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN (Thom Hooijer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale both X_train and X_test\n",
    "X_train_knn = scaler.fit_transform(X_train)\n",
    "X_test_knn = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classifier\n",
    "knnc = KNeighborsClassifier()\n",
    "knnc.fit(X_train_knn, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the classes of the test data\n",
    "y_pred_knn = knnc.predict(X_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test.values, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding classes names for better interpretation\n",
    "classes_names = ratings\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred_knn), \n",
    "                  columns=classes_names, index = classes_names)\n",
    "                  \n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens').set_title('ESRB Rating')\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1s = []\n",
    "\n",
    "# Calculating f1 score for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    # using average='weighted' to calculate a weighted average for the 4 classes \n",
    "    f1s.append(f1_score(y_test, pred_i, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the f1 score for each K value\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), f1s, color='blue', marker='.',\n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('F1 Score K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the f1 score for each K value\n",
    "t = pd.DataFrame(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the maximum f1 score value, this is the optimal K value\n",
    "optimal_n_index_value = t.idxmax().tolist()[0]\n",
    "# Add 1 to fix the index\n",
    "optimal_n_index_value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNN classifier with a optimal k value (K=6)\n",
    "optimal_knn_classifier = KNeighborsClassifier(n_neighbors=optimal_n_index_value)\n",
    "optimal_knn_classifier.fit(X_train, y_train)\n",
    "optimal_knn_pred = optimal_knn_classifier.predict(X_test)\n",
    "print(classification_report(y_test, optimal_knn_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (Remco de Wilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "svclassifier = SVC(kernel='rbf', probability=True)\n",
    "# Train the model\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_svm = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "cm = confusion_matrix(y_test,y_pred_svm)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=ratings, yticklabels=ratings).set_title('ESRB Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Voting Classifier (Remco de Wilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('RF', rfc), ('DT', classifier), ('SVC', svclassifier), ('KNN', optimal_knn_classifier)],\n",
    "                        voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the voting classifier\n",
    "eclf = eclf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_eclf = eclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred_eclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = ratings\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=Labels, yticklabels=Labels).set_title('ESRB Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the classification report\n",
    "print(classification_report(y_test,y_pred_eclf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusie\n",
    "\n",
    "Elk van de geteste machinelearning modellen kan gebruikt worden om een voorspelling te doen. De accuratie van de voorspellingen is echter niet altijd heel hoog. Dit verschilt dan ook wel per model.\n",
    "Uit de vier `Standaard` geteste modellen blijkt dat `Random Forest` de beste resultaten geeft. Dit model heeft een accuracy (en hoogste f1-score)van 0.88. Als nu alle modelen worden gebruikt om tot een `VotingClassifier` te komen dan is de accuracy 0.94 (en de hoogste f1-score). Dit is een stuk hoger dan de andere modellen. Dit model is dus het meest geschikt om te gebruiken om een voorspelling te doen. Onze hoofdvraag `Is het mogelijk om op basis van een aantal voorwaarden te voorspellen dat een game een bepaalde ESRB rating heeft?` kan dus met een `Ja` beantwoord worden. Hierbij moet wel gezegd worden dat de voorspellingen niet altijd heel nauwkeurig zijn. Dit kan mogelijk worden verbeterd door meer data te gebruiken, maar het is uiteraard ook mogelijk dat dit machinelearning model door de aard van de data niet heel nauwkeurig kan voorspellen.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testen voor variabelen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor `max_depth` Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    rfc2 = RandomForestClassifier(n_estimators=20,\n",
    "                                    max_depth=i,\n",
    "                                    random_state=SEED)\n",
    "\n",
    "    rfc2.fit(X_train, y_train)\n",
    "    # Predict the test set labels\n",
    "    y_pred = rfc2.predict(X_test)\n",
    "\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred), mean_squared_error(\n",
    "        y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))], index=['depth', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the results\n",
    "df_depth = pd.DataFrame(data)\n",
    "df_depth.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "df_depth.plot.bar(x='depth', y=['mae', 'mse', 'rmse'], title='Random Forest Classifier',\n",
    "            barmode='group', labels={'value': 'Error', 'depth': 'Depth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De laagste error waarden:\n",
    "df_depth.min()\n",
    "\n",
    "# Conclusie:\n",
    "# Een depth van 17 geeft op alle gemeten punten de laagste error \"rate\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor `n_estimators` Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "n_estimators = np.arange(1, 100, 1)\n",
    "\n",
    "for i in n_estimators:\n",
    "    rfc3 = RandomForestClassifier(n_estimators=i,\n",
    "                                 max_depth=17,\n",
    "                                 random_state=SEED)\n",
    "\n",
    "    # train the model\n",
    "    rfc3.fit(X_train, y_train)\n",
    "    # Predict the test set labels\n",
    "    y_pred = rfc3.predict(X_test)\n",
    "\n",
    "    # Create a series with the calculated metrics and append it to the data list\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred), mean_squared_error(\n",
    "        y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))], index=['n_estimators', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the data list\n",
    "df_n_estim = pd.DataFrame(data)\n",
    "df_n_estim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dataframe\n",
    "df_n_estim.plot(y=['mae', 'mse', 'rmse'], kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_estim.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_estim.idxmin()\n",
    "# Conclussie: The best n_estimators value is 37"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor beste kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "data = []\n",
    "\n",
    "\n",
    "for i in kernel:\n",
    "    svclassifier = SVC(kernel=i, probability=True, random_state=SEED)\n",
    "    svclassifier.fit(X_train, y_train)\n",
    "    y_pred_svm = svclassifier.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_svm), mean_squared_error(y_test, y_pred_svm), np.sqrt(mean_squared_error(y_test, y_pred_svm))], index=['kernel', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_df.plot.bar(x='kernel', barmode=\"group\" , y=['mae', 'mse', 'rmse'], title='Support Vector Machine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concluse: rbf lijkt de beste kernel te zijn voor deze dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor criterion Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cirterion = ['gini', 'entropy']\n",
    "data = []\n",
    "\n",
    "\n",
    "for i in cirterion:\n",
    "    classifier = DecisionTreeClassifier(criterion=i, random_state=SEED)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_tree = classifier.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_tree), mean_squared_error(y_test, y_pred_tree), np.sqrt(mean_squared_error(y_test, y_pred_tree))], index=['kernel', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cirterion_df = pd.DataFrame(data)\n",
    "cirterion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusie: entropy lijkt de beste cirterion te zijn voor deze dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor splitter Decision Tree\n",
    "{“best”, “random”}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = ['best', 'random']\n",
    "data = []\n",
    "\n",
    "\n",
    "for i in splitter:\n",
    "    classifier = DecisionTreeClassifier(splitter=i, random_state=SEED)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_tree = classifier.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_tree), mean_squared_error(y_test, y_pred_tree), np.sqrt(mean_squared_error(y_test, y_pred_tree))], index=['kernel', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_df = pd.DataFrame(data)\n",
    "splitter_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusie: random lijkt de beste splitter te zijn voor deze dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor max_depth Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(1, 20):\n",
    "    classifier = DecisionTreeClassifier(max_depth=i, random_state=SEED)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred_tree = classifier.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_tree), mean_squared_error(y_test, y_pred_tree), np.sqrt(mean_squared_error(y_test, y_pred_tree))], index=['depth', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_df = pd.DataFrame(data)\n",
    "max_depth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_df.plot.bar(x='depth', barmode=\"group\" , y=['mae', 'mse', 'rmse'], title='Decision Tree Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_depth_df.min())\n",
    "print('----')\n",
    "print(max_depth_df.idxmin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusie max_depth 13 lijkt de beste waarde te zijn voor deze dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor algorithm k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "data = []\n",
    "\n",
    "for i in algorithm:\n",
    "    knnc = KNeighborsClassifier(algorithm=i)\n",
    "    knnc.fit(X_train, y_train)\n",
    "    y_pred_knn = knnc.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_knn), mean_squared_error(y_test, y_pred_knn), np.sqrt(mean_squared_error(y_test, y_pred_knn))], index=['algorithm', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_df = pd.DataFrame(data)\n",
    "algorithm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusie: brute (auto) lijkt de beste algorithm te zijn voor deze dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testen voor leaf_size k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafsizes = np.arange(1, 100, 1)\n",
    "data = []\n",
    "\n",
    "for i in leafsizes:\n",
    "    knnc = KNeighborsClassifier(leaf_size=i)\n",
    "    knnc.fit(X_train, y_train)\n",
    "    y_pred_knn = knnc.predict(X_test)\n",
    "    serie = pd.Series([i, mean_absolute_error(y_test, y_pred_knn), mean_squared_error(y_test, y_pred_knn), np.sqrt(mean_squared_error(y_test, y_pred_knn))], index=['algorithm', 'mae', 'mse', 'rmse'])\n",
    "    data.append(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leafsizes_df = pd.DataFrame(data)\n",
    "leafsizes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = leafsizes_df.drop_duplicates(subset=['mae', 'mse', 'rmse'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concluse leafsize lijkt verder geen invloed te hebben op de resultaten"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7918c97c6f7f75d935fcca75698d021b14ddd10448978c88530240ffdf023f85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
